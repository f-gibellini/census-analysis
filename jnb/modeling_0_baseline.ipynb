{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff03fdcf-4535-4d49-af58-5a4f3c0220bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "if not os.path.abspath(os.pardir+ '/src') in sys.path:\n",
    "    sys.path.append(os.path.abspath(os.pardir) + '/src')\n",
    "\n",
    "from data_reader import read_data\n",
    "from features_processor import FeaturesProcessor\n",
    "from ml_experiments import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce5d86c-6b6c-4fc2-8213-1fa057757896",
   "metadata": {},
   "source": [
    "### Read Data and prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c902027-710b-416f-83c4-fc7ab5edb4ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read input data file ../data/census_income_learn.csv\n",
      "Read metadata file ../data/census_income_metadata.txt\n",
      "Couldnt parse line \n",
      "Mapped columns\n",
      "Read input data file ../data/census_income_test.csv\n",
      "Read metadata file ../data/census_income_metadata.txt\n",
      "Couldnt parse line \n",
      "Mapped columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((99762, 41), (199523, 41))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = read_data(DATA_PATH + TRAIN_FNAME, DATA_PATH + METADATA_FNAME, drop_cols = IGNORE_FEATURES)\n",
    "test_df = read_data(DATA_PATH + TEST_FNAME, DATA_PATH + METADATA_FNAME, drop_cols = IGNORE_FEATURES)\n",
    "\n",
    "test_df.shape, train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72024584-9085-4407-8b67-cb8ac1e475b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Numerical Features\n",
      "Encoders not found, creating new encoders\n",
      "Scaling Numerical Features\n",
      "Encoders were found, using existing encoders\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((179570, 404), (19953, 404), (99762, 404))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprocessor = FeaturesProcessor('OHE')\n",
    "\n",
    "encoded_train_df, encoders = fprocessor.transform_features(train_df)\n",
    "encoded_test_df, encoders = fprocessor.transform_features(test_df)\n",
    "\n",
    "encoded_train_df, encoded_val_df = train_test_split(encoded_train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "encoded_train_df.shape, encoded_val_df.shape, encoded_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2269cdf-32fa-4dad-a199-82f12cafacdc",
   "metadata": {},
   "source": [
    "### Run Baseline Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f99cf34-54e2-48b1-ba92-83acf2b30e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0,class_weight=balanced,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=200,multi_class=deprecated,n_jobs=6,penalty=l2,random_state=32,solver=lbfgs,tol=0.0001,verbose=0,warm_start=False)\n",
      "[0.4274240940254652, 0.8927986906710311, 0.2809683234612413, '[[15939   131]\\n [ 2792  1091]]']\n",
      "\n",
      "LogisticRegression(C=1.0,class_weight=balanced,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=500,multi_class=deprecated,n_jobs=6,penalty=l2,random_state=32,solver=lbfgs,tol=0.0001,verbose=0,warm_start=False)\n",
      "[0.4274240940254652, 0.8927986906710311, 0.2809683234612413, '[[15939   131]\\n [ 2792  1091]]']\n",
      "\n",
      "LogisticRegression(C=1.0,class_weight=balanced,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=1000,multi_class=deprecated,n_jobs=6,penalty=l2,random_state=32,solver=lbfgs,tol=0.0001,verbose=0,warm_start=False)\n",
      "[0.4274240940254652, 0.8927986906710311, 0.2809683234612413, '[[15939   131]\\n [ 2792  1091]]']\n",
      "\n",
      "LogisticRegression(C=0.1,class_weight=balanced,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=200,multi_class=deprecated,n_jobs=6,penalty=l2,random_state=32,solver=lbfgs,tol=0.0001,verbose=0,warm_start=False)\n",
      "[0.4171779141104294, 0.8903436988543372, 0.27240861291937907, '[[15825   134]\\n [ 2906  1088]]']\n",
      "\n",
      "LogisticRegression(C=0.1,class_weight=balanced,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=500,multi_class=deprecated,n_jobs=6,penalty=l2,random_state=32,solver=lbfgs,tol=0.0001,verbose=0,warm_start=False)\n",
      "[0.4171779141104294, 0.8903436988543372, 0.27240861291937907, '[[15825   134]\\n [ 2906  1088]]']\n",
      "\n",
      "LogisticRegression(C=0.1,class_weight=balanced,dual=False,fit_intercept=True,intercept_scaling=1,l1_ratio=None,max_iter=1000,multi_class=deprecated,n_jobs=6,penalty=l2,random_state=32,solver=lbfgs,tol=0.0001,verbose=0,warm_start=False)\n",
      "[0.4171779141104294, 0.8903436988543372, 0.27240861291937907, '[[15825   134]\\n [ 2906  1088]]']\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=4,max_features=None,max_leaf_nodes=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,random_state=32,splitter=best)\n",
      "[0.34113816095518684, 0.900163666121113, 0.21044576238760282, '[[14604   122]\\n [ 4127  1100]]']\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=7,max_features=None,max_leaf_nodes=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,random_state=32,splitter=best)\n",
      "[0.4097444089456869, 0.839607201309329, 0.27099841521394613, '[[15971   196]\\n [ 2760  1026]]']\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=10,max_features=None,max_leaf_nodes=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,random_state=32,splitter=best)\n",
      "[0.4067013287117273, 0.8641571194762684, 0.2659279778393352, '[[15816   166]\\n [ 2915  1056]]']\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=13,max_features=None,max_leaf_nodes=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,random_state=32,splitter=best)\n",
      "[0.41349032129315505, 0.8477905073649754, 0.27342306677223543, '[[15978   186]\\n [ 2753  1036]]']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=3,max_features=0.3,max_leaf_nodes=None,max_samples=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,n_estimators=500,n_jobs=6,oob_score=False,random_state=32,verbose=0,warm_start=False)\n",
      "[0.3348498635122839, 0.9034369885433715, 0.20551005212211468, '[[14463   118]\\n [ 4268  1104]]']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=3,max_features=0.3,max_leaf_nodes=None,max_samples=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,n_estimators=1000,n_jobs=6,oob_score=False,random_state=32,verbose=0,warm_start=False)\n",
      "[0.3330316742081448, 0.9034369885433715, 0.20414201183431951, '[[14427   118]\\n [ 4304  1104]]']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=3,max_features=0.3,max_leaf_nodes=None,max_samples=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,n_estimators=1500,n_jobs=6,oob_score=False,random_state=32,verbose=0,warm_start=False)\n",
      "[0.3341375150784077, 0.9067103109656302, 0.20480591497227357, '[[14429   114]\\n [ 4302  1108]]']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=6,max_features=sqrt,max_leaf_nodes=None,max_samples=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,n_estimators=500,n_jobs=6,oob_score=False,random_state=32,verbose=0,warm_start=False)\n",
      "[0.3199771852274348, 0.9181669394435352, 0.19374892073907787, '[[14062   100]\\n [ 4669  1122]]']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=6,max_features=sqrt,max_leaf_nodes=None,max_samples=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,n_estimators=1000,n_jobs=6,oob_score=False,random_state=32,verbose=0,warm_start=False)\n",
      "[0.32235801581595974, 0.9173486088379705, 0.19553462410605268, '[[14119   101]\\n [ 4612  1121]]']\n",
      "\n",
      "RandomForestClassifier(bootstrap=True,ccp_alpha=0.0,class_weight=balanced,criterion=gini,max_depth=6,max_features=sqrt,max_leaf_nodes=None,max_samples=None,min_impurity_decrease=0.0,min_samples_leaf=1,min_samples_split=2,min_weight_fraction_leaf=0.0,monotonic_cst=None,n_estimators=1500,n_jobs=6,oob_score=False,random_state=32,verbose=0,warm_start=False)\n",
      "[0.3233723112458496, 0.9165302782324058, 0.19631901840490798, '[[14146   102]\\n [ 4585  1120]]']\n",
      "\n",
      "CatBoostClassifier(iterations=500,silent=True,task_type=GPU,random_state=32)\n",
      "[0.5828220858895705, 0.4664484451718494, 0.776566757493188, '[[18567   652]\\n [  164   570]]']\n",
      "\n",
      "CatBoostClassifier(iterations=1000,silent=True,task_type=GPU,random_state=32)\n",
      "[0.5790281329923274, 0.46317512274959083, 0.772169167803547, '[[18564   656]\\n [  167   566]]']\n",
      "\n",
      "CatBoostClassifier(iterations=1500,silent=True,task_type=GPU,random_state=32)\n",
      "[0.5833758286588475, 0.46808510638297873, 0.774018944519621, '[[18564   650]\\n [  167   572]]']\n",
      "\n",
      "CatBoostClassifier(iterations=2000,silent=True,task_type=GPU,random_state=32)\n",
      "[0.581799591002045, 0.4656301145662848, 0.7752043596730245, '[[18566   653]\\n [  165   569]]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#feature names\n",
    "feat_names = [col for col in encoded_train_df.columns if (col != TARGET_NAME)]\n",
    "\n",
    "\n",
    "models = [ LogisticRegression(C=1.0, class_weight='balanced', max_iter=200, n_jobs = N_JOBS, random_state=32), #strong regularization, class balancing\n",
    "          LogisticRegression(C=1.0, class_weight='balanced', max_iter=500, n_jobs = N_JOBS, random_state=32), \n",
    "          LogisticRegression(C=1.0, class_weight='balanced', max_iter=1000, n_jobs = N_JOBS, random_state=32), \n",
    "          LogisticRegression(C=0.1, class_weight='balanced', max_iter=200, n_jobs = N_JOBS, random_state=32), #weak regularization, class balancing\n",
    "          LogisticRegression(C=0.1, class_weight='balanced', max_iter=500, n_jobs = N_JOBS, random_state=32), \n",
    "          LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000, n_jobs = N_JOBS, random_state=32), \n",
    "\n",
    "          DecisionTreeClassifier(max_depth=4, class_weight='balanced', random_state=32),\n",
    "          DecisionTreeClassifier(max_depth=7, class_weight='balanced', random_state=32),\n",
    "          DecisionTreeClassifier(max_depth=10, class_weight='balanced', random_state=32),\n",
    "          DecisionTreeClassifier(max_depth=13, class_weight='balanced', random_state=32),\n",
    "\n",
    "          RandomForestClassifier(n_estimators=500, max_depth=3, max_features=0.3, class_weight='balanced', n_jobs=N_JOBS, random_state=32), #try not very deep trees\n",
    "          RandomForestClassifier(n_estimators=1000, max_depth=3, max_features=0.3, class_weight='balanced', n_jobs=N_JOBS, random_state=32),\n",
    "          RandomForestClassifier(n_estimators=1500, max_depth=3, max_features=0.3, class_weight='balanced', n_jobs=N_JOBS, random_state=32),\n",
    "          RandomForestClassifier(n_estimators=500, max_depth=6, n_jobs=N_JOBS, class_weight='balanced', random_state=32), #try deeper trees\n",
    "          RandomForestClassifier(n_estimators=1000, max_depth=6, n_jobs=N_JOBS, class_weight='balanced', random_state=32),\n",
    "          RandomForestClassifier(n_estimators=1500, max_depth=6, n_jobs=N_JOBS, class_weight='balanced', random_state=32),\n",
    "    \n",
    "          CatBoostClassifier(iterations = 500, task_type = 'GPU' if GPU else 'CPU', silent = True, random_state=32),\n",
    "          CatBoostClassifier(iterations = 1000, task_type = 'GPU' if GPU else 'CPU', silent = True,random_state=32),\n",
    "          CatBoostClassifier(iterations = 1500, task_type = 'GPU' if GPU else 'CPU', silent = True,random_state=32),\n",
    "          CatBoostClassifier(iterations = 2000, task_type = 'GPU' if GPU else 'CPU',  silent = True, random_state=32),\n",
    "         \n",
    "         \n",
    "         ]\n",
    "\n",
    "exp_name_base = 'baselines'\n",
    "\n",
    "#folder to store artifacts\n",
    "if not os.path.isdir(MODELS_PATH + exp_name_base):\n",
    "    os.mkdir(MODELS_PATH + exp_name_base)\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    model.fit(encoded_train_df[feat_names], encoded_train_df[TARGET_NAME])\n",
    "\n",
    "    preds = model.predict(encoded_val_df[feat_names])\n",
    "    metrics = evaluate_model(preds, encoded_val_df[TARGET_NAME])\n",
    "    model_name = get_model_string(model)\n",
    "    \n",
    "    log_model(exp_name_base, model_name,\n",
    "             MODELS_PATH + MODELS_LOG_FNAME,\n",
    "             metrics)\n",
    "\n",
    "    save_model_pickle(model, MODELS_PATH + f'{exp_name_base}/' + model_name[:100] + '.pkl')\n",
    "    print(model_name)\n",
    "    print(metrics)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d9b7e-5e1d-4dba-9941-a7630f8279e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba18aca-d463-4267-8dc6-29d70c149879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
